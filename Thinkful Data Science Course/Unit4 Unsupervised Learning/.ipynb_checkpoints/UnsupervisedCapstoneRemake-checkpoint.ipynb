{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data from here: http://share.mailcharts.com/0D0Q2e0L1s47 and http://share.mailcharts.com/0z0F3m1X0l39\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans as KM \n",
    "from sklearn.cluster import AgglomerativeClustering as AG\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\liuth\\Documents\\\\Python Scripts\\\\ThinkfulProjects\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3346, 8)\n",
      "Index(['reg_id', 'add_id', 'name', 'email_guid', 'sent_at', 'subject',\n",
      "       'full_text', 'r'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"capstone-v2.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "df = df.drop_duplicates(\"email_guid\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_id</th>\n",
       "      <th>add_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email_guid</th>\n",
       "      <th>sent_at</th>\n",
       "      <th>subject</th>\n",
       "      <th>full_text</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6361</td>\n",
       "      <td>7526</td>\n",
       "      <td>Le Creuset</td>\n",
       "      <td>45f2d9ed-128e-9ae5-b8f1-4e224a02dfca</td>\n",
       "      <td>2017-01-10 21:34:33</td>\n",
       "      <td>Welcome, Lorem Ipsum!</td>\n",
       "      <td>LE CREUSET Welcome to Le Creuset. To log in wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6361</td>\n",
       "      <td>7526</td>\n",
       "      <td>Le Creuset</td>\n",
       "      <td>34db5cee-2a9c-17f4-b97d-68343ad26f19</td>\n",
       "      <td>2017-01-10 21:36:48</td>\n",
       "      <td>Hi! You were looking for free shipping, right?</td>\n",
       "      <td>Save a bundle on shipping with code LECREUSETL...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6361</td>\n",
       "      <td>7526</td>\n",
       "      <td>Le Creuset</td>\n",
       "      <td>55f96ec8-739f-4a3a-63c4-ec1fddcf795d</td>\n",
       "      <td>2017-01-10 21:41:43</td>\n",
       "      <td>Le Creuset: New Order # 200068673</td>\n",
       "      <td>LE CREUSET Thank you for your order from Le Cr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6361</td>\n",
       "      <td>7526</td>\n",
       "      <td>Le Creuset</td>\n",
       "      <td>f0188d30-aa26-8614-7a44-aa149fad66b0</td>\n",
       "      <td>2017-01-12 21:37:00</td>\n",
       "      <td>Your kitchen + our color choices = food heaven</td>\n",
       "      <td>What will you bring to the table? View in brow...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6361</td>\n",
       "      <td>7526</td>\n",
       "      <td>Le Creuset</td>\n",
       "      <td>29af73ae-8956-9bdc-7148-d5eb0bde173b</td>\n",
       "      <td>2017-01-13 15:09:04</td>\n",
       "      <td>Free Shipping Starts Now + Storage Staples to ...</td>\n",
       "      <td>Plus, a sweet treat for you! LE CREUSET Cookwa...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_id  add_id        name                            email_guid  \\\n",
       "0    6361    7526  Le Creuset  45f2d9ed-128e-9ae5-b8f1-4e224a02dfca   \n",
       "1    6361    7526  Le Creuset  34db5cee-2a9c-17f4-b97d-68343ad26f19   \n",
       "2    6361    7526  Le Creuset  55f96ec8-739f-4a3a-63c4-ec1fddcf795d   \n",
       "3    6361    7526  Le Creuset  f0188d30-aa26-8614-7a44-aa149fad66b0   \n",
       "4    6361    7526  Le Creuset  29af73ae-8956-9bdc-7148-d5eb0bde173b   \n",
       "\n",
       "               sent_at                                            subject  \\\n",
       "0  2017-01-10 21:34:33                              Welcome, Lorem Ipsum!   \n",
       "1  2017-01-10 21:36:48     Hi! You were looking for free shipping, right?   \n",
       "2  2017-01-10 21:41:43                  Le Creuset: New Order # 200068673   \n",
       "3  2017-01-12 21:37:00     Your kitchen + our color choices = food heaven   \n",
       "4  2017-01-13 15:09:04  Free Shipping Starts Now + Storage Staples to ...   \n",
       "\n",
       "                                           full_text  r  \n",
       "0  LE CREUSET Welcome to Le Creuset. To log in wh...  1  \n",
       "1  Save a bundle on shipping with code LECREUSETL...  2  \n",
       "2  LE CREUSET Thank you for your order from Le Cr...  3  \n",
       "3  What will you bring to the table? View in brow...  4  \n",
       "4  Plus, a sweet treat for you! LE CREUSET Cookwa...  5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps: Clean up text, stemming, remove stop words and weird chars, tokenizer words\n",
    "# punctuation = list(set(string.punctuation))\n",
    "re_punctuation = \"\\.|\\>|\\/|\\)|\\\"|\\(|\\}|\\'|\\_|\\-|\\$|\\:|\\[|\\^|\\+|\\?|\\`|\\~|\\!|\\<|\\@|\\;|\\=|\\*|\\\\\\|\\{|\\&|\\]|\\||\\,|\\|\"\n",
    "stopwords_set = list(set(stopwords.words('english')))\n",
    "handpicked_works = [\"com\"]\n",
    "\n",
    "def get_unigram_sentence(sentence, company_name):\n",
    "    company_names = company_name.lower().split(\" \")\n",
    "    company_names.append(company_name.lower().replace(\" \", \"\"))\n",
    "    \n",
    "    sentence_no_punc = re.sub(re_punctuation, \" \", sentence)\n",
    "    unigram = [word for word in word_tokenize(sentence_no_punc.lower()) if word not in stopwords_set and word not in company_names and word not in handpicked_works]\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = []\n",
    "\n",
    "for i, el in df.iterrows():\n",
    "    tokenized_text.append(get_unigram_sentence(el['subject'], el['name']))\n",
    "\n",
    "df[\"tokenized_text\"] = tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_stems(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stemmed_tokens\"] = df.tokenized_text.apply(lambda x: get_stems(x))\n",
    "df[\"stemmed_text\"] = df[\"stemmed_tokens\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=50, ngram_range=(1,2))\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=50)\n",
    "\n",
    "vectorizer = vectorizer.fit(df[\"stemmed_text\"])\n",
    "X = vectorizer.transform(df[\"stemmed_text\"])\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=6, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=22, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_values = X\n",
    "\n",
    "lda = LDA(6, random_state=22)\n",
    "lda.fit(vectorized_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('order', 602.1915256475438), ('confirm', 236.16604261654658), ('way', 90.16608363707132), ('shipment', 56.16655909372359), ('deliveri', 23.05367572445895), ('receiv', 0.16756098036835607), ('thank', 0.16713000518204474), ('ship', 0.16700231862997877), ('account', 0.16681785094785354), ('10', 0.16680792771428085)]\n",
      "====================================================================================================\n",
      "Topic 1:\n",
      "[('thank', 194.1656701073239), ('save', 126.16423957595113), ('gift', 93.16551993348605), ('shop', 92.16497189706146), ('15', 0.35531867285716023), ('order', 0.1674975299517836), ('10', 0.16742602419553165), ('purchas', 0.16742071943010997), ('25', 0.16736771114890517), ('holiday', 0.16732600899418787)]\n",
      "====================================================================================================\n",
      "Topic 2:\n",
      "[('welcom', 303.1656540559297), ('ship', 294.16544958874437), ('free', 168.16424852426377), ('order', 148.14027174193595), ('15', 35.76853519981635), ('10', 0.34035150154350086), ('deliveri', 0.16778540216247048), ('25', 0.16725388319581838), ('end', 0.16715097928250777), ('today', 0.16709417332000442)]\n",
      "====================================================================================================\n",
      "Topic 3:\n",
      "[('sale', 153.34330470836363), ('50', 110.16476386868645), ('today', 99.16397512129613), ('end', 89.16510221575692), ('extra', 83.16512555093466), ('purchas', 75.16489228938251), ('style', 71.16599762271143), ('start', 61.16512431763758), ('25', 47.44603359181044), ('30', 41.04583771014669)]\n",
      "====================================================================================================\n",
      "Topic 4:\n",
      "[('new', 217.16577951334648), ('lorem', 99.16548841648712), ('account', 88.16604885857025), ('10', 74.99103551069301), ('receiv', 51.16560942048222), ('holiday', 49.141086389724634), ('welcom', 0.16717355886552346), ('deliveri', 0.1671380905901758), ('order', 0.1671078437087124), ('shop', 0.16709365943312568)]\n",
      "====================================================================================================\n",
      "Topic 5:\n",
      "[('day', 128.1657441101855), ('20', 84.16553419748197), ('deal', 82.16607600344354), ('30', 39.286613316301725), ('holiday', 15.190514856597716), ('25', 11.885870140037953), ('deliveri', 2.294400202841409), ('sale', 0.9889238141492954), ('today', 0.1682267655222738), ('free', 0.1679369924359991)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        labels.append([(vectorizer.get_feature_names()[i]) for i in topic.argsort()[:-1-1:-1]][0])\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "print_topics(lda, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's assign this to our original text\n",
    "vectorized_values_lda = lda.transform(vectorized_values)\n",
    "predicted_label = []\n",
    "for i in vectorized_values_lda:\n",
    "    # Get the highest value. We'll consider that to be the predicted label.\n",
    "    predicted_label.append(labels[i.argsort()[-1]])\n",
    "df[\"lda_predicted_label\"] = predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('order', 5.606824840852225), ('thank', 0.8316709164353175), ('way', 0.4105117487412752), ('ship', 0.3071491839432591), ('receiv', 0.30191834487859615), ('shipment', 0.16984440795643285), ('10', 0.06529432280049217), ('shop', 0.05165021201837265), ('deliveri', 0.03067125141257726), ('15', 0.023221694060237254)]\n",
      "====================================================================================================\n",
      "Topic 1:\n",
      "[('ship', 3.9381823415025172), ('free', 2.5549554884881016), ('day', 0.3883710977190596), ('10', 0.21359066917282063), ('today', 0.17763187121360932), ('end', 0.14585135710459926), ('50', 0.1428636414713717), ('holiday', 0.13925627594223655), ('25', 0.13825795971340046), ('20', 0.13765613276170413)]\n",
      "====================================================================================================\n",
      "Topic 2:\n",
      "[('welcom', 4.0755596630223), ('lorem', 0.5978172915638713), ('thank', 0.2949135869388419), ('15', 0.263887056248793), ('gift', 0.20149521065157275), ('10', 0.17781138869136037), ('account', 0.17482972344820127), ('purchas', 0.09113878686110366), ('start', 0.0634533974031104), ('20', 0.06134579442708895)]\n",
      "====================================================================================================\n",
      "Topic 3:\n",
      "[('new', 4.061018929182856), ('account', 0.1964622644718691), ('deal', 0.11589288280076616), ('shop', 0.11488643596477957), ('style', 0.10353802666694961), ('sale', 0.05271299411760879), ('30', 0.04898592095021439), ('day', 0.04200111860775085), ('free', 0.032764453241362894), ('start', 0.031263492055024406)]\n",
      "====================================================================================================\n",
      "Topic 4:\n",
      "[('sale', 2.4702802943878326), ('save', 1.3346862213959556), ('day', 1.1932515567720359), ('extra', 1.1925575142546676), ('50', 1.1643985903267218), ('end', 0.8148751180474247), ('today', 0.8003123717575398), ('30', 0.7020577312346037), ('20', 0.5881504595274799), ('shop', 0.5881441706066061)]\n",
      "====================================================================================================\n",
      "Topic 5:\n",
      "[('confirm', 4.387024945666578), ('account', 0.42367982653093583), ('shipment', 0.3126145032164751), ('order', 0.2331281606271442), ('deliveri', 0.18230954750428438), ('lorem', 0.1505716577363927), ('purchas', 0.029630383748227188), ('ship', 0.016924818485809658), ('shop', 0.009299285136745031), ('20', 0.0010149950665927247)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "_model = NMF(6, random_state=22)\n",
    "_model.fit(vectorized_values)\n",
    "\n",
    "labels = []\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i]) for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        labels.append([(vectorizer.get_feature_names()[i]) for i in topic.argsort()[:-1-1:-1]][0])\n",
    "        print(\"=\" * 100)\n",
    "print_topics(_model, vectorizer)\n",
    "\n",
    "vectorized_values_model = _model.transform(vectorized_values)\n",
    "\n",
    "predicted_label = []\n",
    "for i in vectorized_values_model:\n",
    "    # Get the highest value. We'll consider that to be the predicted label.\n",
    "    predicted_label.append(labels[i.argsort()[-1]])\n",
    "\n",
    "df[\"nmf_predicted_label\"] = predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = KM(6, random_state=22)\n",
    "_model.fit(vectorized_values)\n",
    "\n",
    "labels = []\n",
    "def print_topics(model, vectorizer, top_n=3):\n",
    "    for i, t in enumerate(_model.cluster_centers_):\n",
    "        top_words = t.argsort()[:-3:-1]\n",
    "#         for w in top_words:\n",
    "#             print(vectorizer.get_feature_names()[w])\n",
    "        labels.append(vectorizer.get_feature_names()[top_words[0]])\n",
    "#         print(\"=\" * 100)\n",
    "print_topics(_model, vectorizer)\n",
    "\n",
    "vectorized_values_model = _model.transform(vectorized_values)\n",
    "\n",
    "predicted_label = []\n",
    "for i in vectorized_values_model:\n",
    "    # Get the highest value. We'll consider that to be the predicted label.\n",
    "    predicted_label.append(labels[i.argsort()[-1]])\n",
    "\n",
    "df[\"km_predicted_label\"] = predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1717\n",
      "1     206\n",
      "Name: order confirmation, dtype: int64\n",
      "0.0    1769\n",
      "1.0     154\n",
      "Name: shipping confirmation, dtype: int64\n",
      "0.0    1906\n",
      "1.0      17\n",
      "Name: delivery notification, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Load manual classification\n",
    "classified = pd.read_csv(\"captsone-manually-classified.csv\")\n",
    "\n",
    "# Fill blanks with 0\n",
    "classified.fillna(0, inplace=True)\n",
    "\n",
    "# Remove any \"?\" and replace with 0\n",
    "classified[\"order confirmation\"][classified[\"order confirmation\"] == \"?\"] = 0\n",
    "\n",
    "# Print some quick summary stats\n",
    "print(classified[\"order confirmation\"].value_counts())\n",
    "print(classified[\"shipping confirmation\"].value_counts())\n",
    "print(classified[\"delivery notification\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_classification_results(row):\n",
    "    if row[\"order confirmation\"] != 0:\n",
    "        return \"order\"\n",
    "    if row[\"shipping confirmation\"] != 0:\n",
    "        return \"ship\"\n",
    "    if row[\"delivery notification\"] != 0:\n",
    "        return \"delivery\"\n",
    "    else:\n",
    "        return \"not classified\"\n",
    "\n",
    "classified[\"manual_label\"] = classified.apply(get_classification_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "manual_df = classified.drop_duplicates(\"email_guid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(manual_df[[\"email_guid\", \"manual_label\"]], on=\"email_guid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not classified    1539\n",
       "order              205\n",
       "ship               151\n",
       "delivery            17\n",
       "Name: manual_label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"manual_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.manual_label.fillna(\"not classified\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only focus on emails classified manually\n",
    "\n",
    "indices = df[df.manual_label != \"not classified\"].index\n",
    "y_class = df.loc[indices, \"manual_label\"]\n",
    "X_class = X[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_class, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  12,   5],\n",
       "       [  0, 205,   0],\n",
       "       [  0,   9, 142]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_class, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9302949061662198"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_class, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order       205\n",
       "ship        151\n",
       "delivery     17\n",
       "Name: manual_label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = df.loc[indices, \"r\"]\n",
    "X_r = list(X_r)\n",
    "X_df[\"r\"] = X_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_df, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436997319034852"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_df, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   5,   5],\n",
       "       [  1, 203,   1],\n",
       "       [  0,   9, 142]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_class, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_df, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705093833780161"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_df, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rf.predict(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,   3,   2],\n",
       "       [  0, 205,   0],\n",
       "       [  1,   5, 145]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_class, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run against topic modeling\n",
    "y = df.lda_predicted_label\n",
    "X_df = pd.DataFrame(X)\n",
    "X_df[\"r\"] = df.r.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916301315265046"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984468339307049"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[292,   2,   0,   2,   1,   2],\n",
       "       [  0,  91,   0,   1,   0,   0],\n",
       "       [  0,   0, 120,   0,   0,   1],\n",
       "       [  0,   0,   2, 109,   0,   0],\n",
       "       [  0,   0,   0,   0,  72,   0],\n",
       "       [  0,   0,   2,   0,   0, 140]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validate possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.93181818, 0.95348837, 0.93975904, 0.92771084, 0.89156627,\n",
       "       0.93975904, 0.92771084, 0.91566265, 0.93975904, 0.98780488])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
