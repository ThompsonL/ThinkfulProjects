{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X2 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno', 'agea', 'happy', 'tvtot'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X2 = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X2.shape[0] * 0.8)\n",
    "\n",
    "# Put 80% of the data in the training set.\n",
    "X2_train, y_train = X2[:offset], y[:offset]\n",
    "\n",
    "# And put 20% in the test set.\n",
    "X2_test, y_test = X2[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  \\\n",
      "0        6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0   \n",
      "1        6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0   \n",
      "2        6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0   \n",
      "3        6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0   \n",
      "4        6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0   \n",
      "6        6    3.0      0.0      5.0     2.0    0.0      2.0     2.0   1.0   \n",
      "7        6    2.0      4.0      5.0     3.0   10.0      5.0     2.0   2.0   \n",
      "8        6    2.0      8.0      8.0     8.0    9.0      6.0     4.0   2.0   \n",
      "9        6    4.0      4.0      4.0     8.0    7.0      4.0     2.0   2.0   \n",
      "10       6    1.0      6.0      7.0     7.0    9.0      5.0     2.0   2.0   \n",
      "11       6    4.0      5.0      7.0     7.0    7.0      5.0     3.0   1.0   \n",
      "12       6    4.0      7.0      7.0     4.0    9.0      6.0     2.0   1.0   \n",
      "13       6    2.0      1.0      9.0     7.0    8.0      4.0     3.0   1.0   \n",
      "14       6    4.0      4.0      5.0     3.0    8.0      1.0     2.0   2.0   \n",
      "15       6    5.0      4.0      5.0     5.0    9.0      3.0     3.0   2.0   \n",
      "16       6    4.0      5.0      7.0     7.0    8.0      3.0     3.0   1.0   \n",
      "17       6    2.0      7.0      7.0     7.0    6.0      6.0     3.0   1.0   \n",
      "18       6    0.0      9.0      7.0     8.0    9.0      5.0     4.0   1.0   \n",
      "19       6    2.0      6.0      6.0     6.0    8.0      4.0     3.0   2.0   \n",
      "20       6    7.0      3.0      4.0     4.0    7.0      6.0     4.0   1.0   \n",
      "21       6    1.0      8.0      8.0     6.0    8.0      7.0     4.0   1.0   \n",
      "22       6    2.0      7.0      7.0     8.0    9.0      6.0     3.0   1.0   \n",
      "23       6    2.0      4.0      8.0     8.0    9.0      6.0     2.0   2.0   \n",
      "24       6    0.0      7.0      7.0     4.0    9.0      4.0     2.0   2.0   \n",
      "25       6    0.0      6.0      7.0     5.0    7.0      6.0     2.0   2.0   \n",
      "26       6    2.0      7.0      6.0     5.0    8.0      4.0     3.0   2.0   \n",
      "27       6    0.0      5.0      8.0     6.0    9.0      4.0     2.0   2.0   \n",
      "28       6    2.0      8.0      8.0     8.0   10.0      6.0     3.0   2.0   \n",
      "29       6    7.0      8.0      5.0     5.0    8.0      5.0     3.0   2.0   \n",
      "30       6    6.0      8.0      8.0     3.0    5.0      6.0     1.0   2.0   \n",
      "...    ...    ...      ...      ...     ...    ...      ...     ...   ...   \n",
      "8564     7    2.0      1.0      5.0     4.0   10.0      7.0     4.0   1.0   \n",
      "8565     7    5.0      5.0      3.0     4.0    5.0      6.0     1.0   2.0   \n",
      "8566     7    2.0      7.0      8.0     6.0    8.0      7.0     3.0   2.0   \n",
      "8567     7    2.0      4.0      8.0     7.0    9.0      7.0     4.0   2.0   \n",
      "8568     7    1.0      2.0      8.0     6.0    9.0      7.0     3.0   2.0   \n",
      "8569     7    6.0      5.0      3.0     4.0    9.0      6.0     4.0   1.0   \n",
      "8570     7    1.0      5.0      7.0     7.0    8.0      7.0     4.0   1.0   \n",
      "8571     7    3.0      4.0      9.0     7.0    8.0      6.0     3.0   1.0   \n",
      "8572     7    5.0      7.0      8.0     5.0    8.0      3.0     1.0   1.0   \n",
      "8573     7    1.0      8.0      8.0     6.0    9.0      7.0     3.0   2.0   \n",
      "8574     7    1.0      4.0      5.0     6.0    7.0      7.0     3.0   2.0   \n",
      "8575     7    3.0      8.0      7.0     7.0    8.0      7.0     3.0   1.0   \n",
      "8576     7    4.0      5.0      4.0     4.0    7.0      6.0     3.0   1.0   \n",
      "8577     7    6.0      6.0      9.0     7.0    5.0      4.0     2.0   2.0   \n",
      "8578     7    1.0      5.0      5.0     5.0    7.0      5.0     4.0   2.0   \n",
      "8579     7    2.0      8.0      9.0     7.0    9.0      7.0     3.0   2.0   \n",
      "8580     7    4.0      7.0      8.0     5.0   10.0      4.0     1.0   1.0   \n",
      "8581     7    1.0      6.0      7.0     6.0    8.0      6.0     3.0   1.0   \n",
      "8582     7    6.0      7.0      7.0     6.0    8.0      7.0     3.0   1.0   \n",
      "8583     7    2.0      6.0      8.0     5.0   10.0      6.0     5.0   1.0   \n",
      "8584     7    2.0      8.0     10.0     6.0    9.0      6.0     2.0   1.0   \n",
      "8585     7    1.0      3.0      6.0     4.0    9.0      7.0     3.0   1.0   \n",
      "8586     7    2.0      4.0      6.0     3.0    7.0      7.0     3.0   2.0   \n",
      "8587     7    4.0      4.0      6.0     7.0    9.0      7.0     3.0   1.0   \n",
      "8588     7    1.0      6.0      5.0     5.0   10.0      7.0     2.0   1.0   \n",
      "8589     7    3.0      4.0      5.0     3.0    6.0      6.0     2.0   1.0   \n",
      "8590     7    5.0      6.0      4.0     4.0   10.0      6.0     3.0   1.0   \n",
      "8591     7    4.0      5.0      7.0     6.0    8.0      6.0     3.0   1.0   \n",
      "8592     7    5.0      8.0      8.0     6.0    9.0      7.0     3.0   1.0   \n",
      "8593     7    2.0      6.0      7.0     5.0    7.0      7.0     4.0   2.0   \n",
      "\n",
      "      agea  ...  DE  ES  NO  SE  CH  CZ  DE  ES  NO  SE  \n",
      "0     60.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "1     59.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "2     24.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "3     64.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "4     55.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "6     76.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "7     30.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "8     84.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "9     62.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "10    33.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "11    40.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "12    69.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "13    59.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "14    32.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "15    70.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "16    61.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "17    30.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "18    21.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "19    36.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "20    51.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "21    25.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "22    62.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "23    20.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "24    22.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "25    32.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "26    35.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "27    26.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "28    35.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "29    54.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "30    38.0  ...   0   0   0   0   1   0   0   0   0   0  \n",
      "...    ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "8564  17.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8565  17.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8566  17.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8567  17.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8568  17.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8569  17.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8570  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8571  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8572  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8573  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8574  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8575  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8576  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8577  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8578  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8579  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8580  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8581  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8582  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8583  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8584  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8585  16.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8586  15.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8587  15.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8588  15.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8589  18.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8590  15.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8591  44.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8592  15.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "8593  15.0  ...   0   0   0   1   0   0   0   0   0   1  \n",
      "\n",
      "[8147 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak learner 0 R^2: 0.5964158585982571\n",
      "Weak learner 20 R^2: 0.732048606849147\n",
      "Weak learner 40 R^2: 0.732048606849147\n",
      "Weak learner 60 R^2: 0.732048606849147\n",
      "Weak learner 80 R^2: 0.732048606849147\n",
      "Weak learner 100 R^2: 0.732048606849147\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl0FAW2x/HvJWEH2RMCIQISlYAsEkDH0QERRRxhVBQQBQFlVJBNHdBhBkHFoLKLC0/2UVFQAZVlEOXpUxECbgho2JQAJkBYAoF0lvv+6CaGGNIJpFJJ537O4ZDqrur8Cj35paq7bomqYowxxuSljNsBjDHGFH9WFsYYY/yysjDGGOOXlYUxxhi/rCyMMcb4ZWVhjDHGLysLY4wxfllZGGOM8cvKwhhjjF/BbgcoLLVr19aGDRu6HcMYY0qUTZs2HVLVOv7WC5iyaNiwIbGxsW7HMMaYEkVEfsnPenYayhhjjF9WFsYYY/yysjDGGONXwLxnkZu0tDTi4+M5ffq021EKVYUKFQgPD6ds2bJuRzHGlBIBXRbx8fFUrVqVhg0bIiJuxykUqsrhw4eJj4+nUaNGbscxxpQSAX0a6vTp09SqVStgigJARKhVq1bAHS0ZY4o3R8tCRLqIyE8iskNERufy/IMi8oOIfCsi/yciUb7HG4rIKd/j34rIqxeQ4UJ2oVgKxH0yxhRvjp2GEpEgYCbQGYgHNorIclXdmm21N1X1Vd/63YDJQBffcztVtZVT+YwxJhDMHTkcz4nT/H3Wef9OnS9OHlm0A3ao6i5V9QCLgO7ZV1DV49kWKwMBeUPwVatWcdlll9GkSRNiYmLcjmOMCQCb1q5meu/+JO3bwanjKaSmpDj6/Zx8g7s+sDfbcjzQPudKIjIYGAmUA67P9lQjEfkGOA6MUdXPHczqmIyMDAYPHsyaNWsIDw+nbdu2dOvWjaioKLejGWNKoDSPh7nDhpOclACkUaF8Xe6ZEkP5SpUc/b5OlkVuJ9b/cOSgqjOBmSJyNzAG6AccACJU9bCItAGWikizHEciiMggYBBAREREYecvFBs2bKBJkyY0btwYgF69erFs2TIrC2NMgX3+/ttsfmcl6ZmHCJKaXHp9O7oOGlIk39vJsogHGmRbDgf257H+IuAVAFVNBVJ9X28SkZ3ApcBZw59UdRYwCyA6OjrPU1jjPviRrfuP57VKgUXVu4ixtzbLc519+/bRoMHv/wzh4eF8/fXXhZrDGBPYUlNSmPvICE6eSASUSpXr0XfaJCpXrVpkGZwsi41ApIg0AvYBvYC7s68gIpGqGudbvAWI8z1eB0hS1QwRaQxEArsczOoY1T92mH2ayRiTX6vnvsq21V+SoUkESy1adO9Ex959izyHY2WhqukiMgRYDQQBc1T1RxEZD8Sq6nJgiIjcAKQBR/CeggK4DhgvIulABvCgqiZdSB5/RwBOCQ8PZ+/e39+6iY+Pp169eq5kMcaUHMlHklg4YhSnTiUCQVSpHs6AGdMpW66cK3kcvYJbVVcAK3I89u9sXw87x3bvAu86ma2otG3blri4OHbv3k39+vVZtGgRb775ptuxjDHF2NKpL7B7/Xdk6lHKlqnDVf1uo12Xbq5mCuhxH8VBcHAwL730EjfddBMZGRkMGDCAZs3cOcoxxhRvh/bv5e1R4zjtSUSkHNVDGtJ30mTXjiays7IoAl27dqVr165uxzDGFGOLnh7LgR/jyNTjlC0Twg3D7iPqquvcjpXFysIYY1z0y/YtfPD0FFLTExCpTO2Gl9Nv4otux/oDKwtjjHHJgtGPc2jPXlRPUC44lFueGErj5i3djpUrKwtjjCliWzd8ydqpr+PJSKSMXERYVCt6j33G7Vh5srIwxpgiNHvYUI4lHED1NBXKhtLjuX8R2qCh27H8srIwxpgisPG/H/LV3HdJyzxIGalOw3ZtuP3RP9y5odiysjDGGAeleTzMfWQoyUcPAulUrFCXPpNjqFarttvRCiSg75RXHOzdu5eOHTvStGlTmjVrxrRp0wBISkqic+fOREZG0rlzZ44cOeJyUmNMYVu3+A1e7juI5KPxBEllmt5wIw/Pf73EFQVYWTguODiYSZMmsW3bNtavX8/MmTPZunUrMTExdOrUibi4ODp16mT3uTAmgKSmpPDKwAfYtGQx6XqUSlXCeGjOq3R9YLDb0c6bnYZyWFhYGGFhYQBUrVqVpk2bsm/fPpYtW8a6desA6NevHx06dGDixIkuJjXGFIZVs19h+5qvfIP/atPyjs50uLOP27EuWOkpi5Wj4bcfCvc1614BN+f/iGDPnj188803tG/fnoSEhKwSCQsLIzExsXCzGWOK1LHDh3hj5GhOnT4IBFO1RgP6T59WLEZ1FIbSUxYuO3HiBHfccQdTp07loosucjuOMaYQvTcphl82bska/Hf1gDtp2zmwRvyUnrIowBFAYUtLS+OOO+6gT58+3H777QCEhoZy4MABwsLCOHDgACEhIa7lM8acn4S9e1j8xDOkpiUgUoHqdRsxcNoMt2M5ovSUhUtUlYEDB9K0aVNGjhyZ9Xi3bt2YP38+o0ePZv78+XTv3t3FlMaYgnpr3Bh+27aTTE2mXFAInYbfT1S7P7kdyzFWFg774osvWLhwIVdccQWtWrUCYMKECYwePZq77rqL2bNnExERweLFi11OaozJj11bvuOj56bjSU9ApAp1GjWlb8wLbsdynJWFw/785z/nemtVgLVr1xZxGmPMhZg/6jEO/7IX1ZOUDw7l1n+N4OLLm7sdq0hYWRhjjB9bvljHJy8tIC3TO/ivXvM29PrXOLdjFSkrC2OMOYc0j4cFj47k2MHfUPVQoVxdek4cS+16DdyOVuSsLIwxJhcbVi1n/fz3Scs8SJDUoOHV7fnb8MfdjuUaKwtjjMkmzeNhziNDOXE0EcigYsUw7p0ykao1arodzVVWFsYY4/PpWwv4ftla0vUwQVKTpjf9iZv6P+h2rGLB0bIQkS7ANCAIeF1VY3I8/yAwGMgATgCDVHWr77kngIG+54aq6monsxpjSq+TycksGPYoKScTAaFylfr0nzGF8pUquR2t2HBs6qyIBAEzgZuBKKC3iETlWO1NVb1CVVsBzwOTfdtGAb2AZkAX4GXf65VYGRkZtG7dmr/+9a8A7N69m/bt2xMZGUnPnj3xeDwuJzSmdPro1en8zwODSTm5n+Ay1WnXqxcPzn7NiiIHJ0eUtwN2qOouVfUAi4CzLlNW1ePZFisDZy5I6A4sUtVUVd0N7PC9Xok1bdo0mjZtmrU8atQoRowYQVxcHDVq1GD27NkupjOm9Dl2+BAz+97P9k8/JkNPclHNCB6eP4trb+vpdrRiycmyqA/szbYc73vsLCIyWER24j2yGFqQbUuK+Ph4PvroI+6//37AOwLkk08+oUePHoB3RPnSpUvdjGhMqfLuCxOYM3gYp1N/o2yZWnQYNIgHXnk5YCbEOsHJ9ywkl8f+cCmzqs4EZorI3cAYoF9+txWRQcAggIiIiDzDTNwwke1J2/2nLoDLa17OqHaj/K43fPhwnn/+eZKTkwE4fPgw1atXJzjY+88fHh7Ovn37CjWbMeaPDuzZybtjJpCalohIBWrUu4QBU6a5HatEcLIs4oHsV66EA/vzWH8R8EpBtlXVWcAsgOjo6Nxnarjsww8/JCQkhDZt2mTd7Ci38R8iufWjMaawvDH2SRJ/2p01+K/zo3/n8jbt3Y5VYjhZFhuBSBFpBOzD+4b13dlXEJFIVY3zLd4CnPl6OfCmiEwG6gGRwIYLCZOfIwAnfPHFFyxfvpwVK1Zw+vRpjh8/zvDhwzl69Cjp6ekEBwcTHx9PvXr1XMlnTKDb+f1mVsbMJDXDO/gv5JIo7p3wvNuxShzHykJV00VkCLAa70dn56jqjyIyHohV1eXAEBG5AUgDjuA9BYVvvXeArUA6MFhVM5zK6qTnnnuO5557DoB169bx4osv8sYbb3DnnXeyZMkSevXqZSPKjXHIvMdGkhQfj+opygeH8renHiU8MueHMk1+OHqdhaquAFbkeOzf2b4else2zwLPOpfOXRMnTqRXr16MGTOG1q1bM3DgQLcjGRMwvv/8U9a9vDBr8F94y2juenKs27FKNLuCuwh16NCBDh06ANC4cWM2bLigM2vGmBzSPB7mjxzB8UMJpX7wX2GzsjDGBISvP1rK+v8sI903+K/xn6+m2yOPuh0rYFhZGGNKtDSPhzmDH+HE8YPY4D/nWFkYY0qsj/8zmx8//Ix0PUyw1CLq5mvp3O9+t2MFJCsLY0yJczI5mflDR3Iq5SBQhsoX1af/NBv85yQrC2NMifLBzCns/HwzGXqE4DK1ie51C9d0v9PtWAHPysIYUyIkJfzGW4+P4XRqIlCOi2pfzH1Tptg8pyJiZVEEjh49yv3338+WLVsQEebMmcNll11Gz5492bNnDw0bNuSdd96hRo0abkc1plhaHPMM8d9uI1OPUbZMCNf9vTetOnR2O1ap4uTUWeMzbNgwunTpwvbt2/nuu+9o2rQpMTExdOrUibi4ODp16kRMTIz/FzKmlNm/M46X+gzk12++RkmjZv1Ihr41x4rCBXZk4bDjx4/z2WefMW/ePADKlStHuXLlWLZsWdZgwX79+tGhQwcmTpzoXlBjipn/jBlF4o5fUD1BuaBQuvzjISJbRbsdq9QqNWXx24QJpG4r3BHl5ZteTt0nn8xznV27dlGnTh369+/Pd999R5s2bZg2bRoJCQmEhYUBEBYWRmJiYqFmM6akivs2llXPv4wnIxGRqoRe2px7nrYjb7eVmrJwS3p6Ops3b2bGjBm0b9+eYcOG2SknY85h7sgRHNm/zzv4r2wot48bTb1LIt2OZShFZeHvCMAp4eHhhIeH0769d25+jx49iImJITQ0lAMHDhAWFsaBAwcICQlxJZ8xxcG369bw2Wtv+Qb/VaNB6xbcOXqM27FMNqWmLNxSt25dGjRowE8//cRll13G2rVriYqKIioqivnz5zN69GgbUW5KrTSPh7nDh5N8OAFIo0L5uvR+4RlqhtZ1O5rJwcqiCMyYMYM+ffrg8Xho3Lgxc+fOJTMzk7vuuovZs2cTERHB4sWL3Y5pTJH6YtliYhd9RHrmIYKkBk3+Es1fHzrnXQuMy6wsikCrVq2IjY39w+Nr1651IY0x7kpNSWHu0OGcTD4IKJUqhdF3+mQqV63qdjSTBysLY0yR+e/819i68ksyfIP/mt/akU597nM7lskHKwtjjOOSjySxcMQoTp1KBIKoUi2cAS9Nt1EdJYiVhTHGUcumv8juL7/zDf6rw1X3dKf9LX9zO5YpICsLY4wjDu3fy9ujxnHak4hIOarVaUi/yZPtaKKEsrIwxhS6t599iv0//EymHqdsmRCuH9KX5td0cDuWuQBWFsaYQhMft5WlT00iNT0BkcrUiriU+16Y7HYsUwgcnTorIl1E5CcR2SEio3N5fqSIbBWR70VkrYhcnO25DBH51vdnuZM5nTZlyhSaNWtG8+bN6d27N6dPn2b37t20b9+eyMhIevbsicfjcTumMRdk4ZP/4J1/jSc1PYHyQaF0f3KUFUUAcawsRCQImAncDEQBvUUkKsdq3wDRqtoCWAI8n+25U6rayvenm1M5nbZv3z6mT59ObGwsW7ZsISMjg0WLFjFq1ChGjBhBXFwcNWrUYPbs2W5HNea8bN/0NTPuHkDizq0IQt3LWzDkzdlc0uJKt6OZQuTkkUU7YIeq7lJVD7AIOGumhap+qqopvsX1QLiDeVyTnp7OqVOnSE9PJyUlhbCwMD755BN69OgBeEeUL1261OWUxhTcnBHDWPHCi3gyDlK+bCi9Yp6hz7gJbscyDnDyPYv6wN5sy/FA+zzWHwiszLZcQURigXQgRlX/8NNURAYBgwAiIiLyDPP5Oz9zaO+J/CXPp9oNqnDtXZfmuU79+vV57LHHiIiIoGLFitx44420adOG6tWrExzs/ecPDw9n3759hZrNGCdtXLOCr+Ys8Q3+q87F0a2543F3hnWaouFkWUguj2muK4rcA0QDf8n2cISq7heRxsAnIvKDqu4868VUZwGzAKKjo3N9bbcdOXKEZcuWsXv3bqpXr86dd97JypUr/7CeSG7/XMYUL2keD3OHDSM5KZEzg//umRJDtVq13Y5mHOZkWcQDDbIthwP7c64kIjcA/wT+oqqpZx5X1f2+v3eJyDqgNbAz5/b55e8IwCkff/wxjRo1ok6dOgDcfvvtfPnllxw9epT09HSCg4OJj4+nXr16ruQzJr8+e+8tvlm82jf4ryaXXt+OroOGuB3LFBEn37PYCESKSCMRKQf0As76VJOItAZeA7qpamK2x2uISHnf17WBa4CtDmZ1TEREBOvXryclJQVVzRpR3rFjR5YsWQJgI8pNsZaaksKrAwex8e13SM88SqUq9Xjgf2ZaUZQyjh1ZqGq6iAwBVgNBwBxV/VFExgOxqroceAGoAiz2nYb51ffJp6bAayKSibfQYlS1RJZF+/bt6dGjB1deeSXBwcG0bt2aQYMGccstt9CrVy/GjBlD69atGThwoNtRjfmD1XNfZdvqL8nQJIKlFi1uu4GOPe91O5ZxgagWy1P9BRYdHa05x4Bv27aNpk2bupTIWYG8b8Z9fxj8Vz2EATNs8F8gEpFNqhrtbz27gtsYc5b3p0xkz9c/kKlHKVumDlf1u412XUrspU6mkFhZGGMASNi7hyVPPu0b/FeB6qGNGDh9htuxTDFhZWGMYdHTYznwY1zW4L8bht1H1FXXuR3LFCNWFsaUYr9s38IHT0/JGvxXu+Hl9Jv4otuxTDFkZWFMKbVg9GMc2rMX1ZOUCw7llieG0rh5S7djmWLKysKYUmbr+s9YO30enoxEyshFhEW1ovfYZ9yOZYo5R0eUG68BAwYQEhJC8+bNsx5LSkqic+fOREZG0rlzZ44cOQKAqjJ06FCaNGlCixYt2Lx5s1uxTQCaPfQRVk2dgSfjIBXKhXL3CxOsKEy+WFkUgfvuu49Vq1ad9VhMTAydOnUiLi6OTp06ERMTA8DKlSuJi4sjLi6OWbNm8dBDD7kR2QSYjf/9kOm9+3M0YTdCeRpf9WcGL5xNaIOGbkczJYSdhioC1113HXv27DnrsWXLlrFu3TrAO6K8Q4cOTJw4kWXLltG3b19EhKuuuoqjR49y4MABwsLCij64KfHSPB7mPDKUE0cPAulUrFiXPpNs8J8puDzLQkRG5vW8qpaY22B9Om8Wib/sKtTXDLm4MR3vG3Re2yYkJGQVQFhYGImJ3tFY+/bto0GD3+cvnhlfbmVhCurTtxfy/ftrSVfv4L/LO19Nl4F2pGrOj78ji6q+vy8D2vL7IMBbgc+cClWa5TZ+xcaXm4JITUlhziPDSTmRCAiVq9Sj/4yplK9Uye1opgTLsyxUdRyAiPwXuFJVk33LTwGLHU9XiM73CMApoaGhWaeXDhw4QEhICOA9kti79/d7Rtn4clMQK/5nJj+v/do3+K82Le/oTIc7+7gdywSA/L7BHQF4si17gIaFnqYU6datG/PnzwfOHlHerVs3FixYgKqyfv16qlWrZqegjF/HDh9iZt/72fbxajL0JFVrNODhBbOsKEyhye8b3AuBDSLyPt673d0GLHAsVYDp3bs369at49ChQ4SHhzNu3DhGjx7NXXfdxezZs4mIiGDxYu+BWteuXVmxYgVNmjShUqVKzJ071+X0prh798Xn+DX2x6zBf1cPuJO2nbu6HcsEmHyPKBeRK4FrfYufqeo3jqU6Dzai3JQ2B/bs5N0xz5GaloBIBaqFhjFw2nS3Y5kSxokR5ZWA46o6V0TqiEgjVd19/hGNMefrrXFj+G3bTjI1mXJBIXQafj9R7f7kdiwTwPJVFiIyFojG+6mouUBZ4D94b3dqjCkiu7Z8x0fPTceTnoBIFUIaR3Hvc8+7HcuUAvk9srgNaA1sBlDV/SJSNe9NigdVDbiPngbK3Q1Nwcx7fCRJe/ehepLywaHc+q8RXHx5c/8bGlMI8lsWHlVVEVEAEansYKZCU6FCBQ4fPkytWrUCpjBUlcOHD1OhQgW3o5gisuWLdXzy0gLSMr2D/+pdEU2vMU+5HcuUMvkti3dE5DWguog8AAwAXncuVuEIDw8nPj6egwcPuh2lUFWoUIHw8HC3YxiHpXk8zH90JMcP/oaqhwrl6tJz4lhq12vgf2NjClm+ykJVXxSRzsBxvO9b/FtV1ziarBCULVuWRo0auR3DmALbsGo56+e/T1rmQYKkBg2vbs/fhj/udixTiuX3De6JqjoKWJPLY3lt1wWYBgQBr6tqTI7nRwL3A+nAQWCAqv7ie64fMMa36jOqOj9/u2RMyfX74L9EIIOKFety75TnqVqjptvRTCmX3yu4O+fy2M15bSAiQcBM33pRQG8Ricqx2jdAtKq2AJYAz/u2rQmMBdoD7YCxIlIjn1mNKZHWvjGPl/s+wImj8QRJFZp3uZmH571uRWGKBX9TZx8CHgYuEZHvsz1VFfjSz2u3A3ao6i7fay0CugNbz6ygqp9mW389cI/v65uANaqa5Nt2DdAFeMvfDhlT0pxMTmbB0JGkpBwEhMpV69F/ug3+M8WLv9NQbwIrgeeA0dkeTz7zgzwP9YG92Zbj8R4pnMtA3/c617b1/Xw/Y0qcj16dTty6jWToEYLL1ObKu27m2tt6uh3LmD/wN3X2GHBMRKYBSdmmzlYVkfaq+nUem+f2WdVcLxAQkXvwXvT3l4JsKyKDgEEAEREReUQxpnhJSviNtx4fw+nURKAsF9WM4L5pUylbrpzb0YzJVX4/OvsKcGW25ZO5PJZTPJD9M37hwP6cK4nIDcA/gb+oamq2bTvk2HZdzm1VdRYwC7yzofzsgzHFwpLnn2Xv5q1k6jHKlgnhmvt70qbTTW7HMiZP+S0L0WyXDatqpoj423YjECkijYB9QC/g7rNeVKQ18BrQRVUTsz21GpiQ7U3tG4En8pnVmGLJO/hvAqlpiYhUpGb9JvSfPNXtWMbkS37LYpeIDMV7NAHeN73zvEepqqaLyBC8P/iDgDmq+qOIjAdiVXU58AJQBVjsu8L6V1XtpqpJIvI03sIBGJ+P90iMKbbe+PeTJP68O2vwX+dH/87lbfJ6C8+Y4iVfI8pFJASYDlyP972DtcDwHEcDrsptRLkxbtv5/WZWTHwJT3oiIlWoc8nF3PvsRLdjGZOlUEeU+0qh1wWnMqYUmffoCJL27UP1FOWDQ7l9/GjqXRLpdixjzou/6yz+oarPi8gMcvk0kqoOdSyZMSXU959/yrqXF/oG/1UjvGUz7npyrNuxjLkg/o4stvn+tvM7xviR5vEwb8QIjh9KALyD/3q/+Aw1Q+u6Hc2YC+bvOosPfH/bXCZj8vDVB++x4c0PSPcN/mt8zdV0e+RRt2MZU2j8nYb6gHNcSAegqt0KPZExJUiax8OcwY9w4vhBIJOKFcPoN2MylauWiHuDGZNv/k5Dvej7+3agLt5bqQL0BvY4lMmYEuHj/8zmx48+Iz3zMMFSi6ibr6Vzv/vdjmWMI/ydhvpfABF5WlWvy/bUByLymaPJjCmmTiYnM3/oSE6lHATKUOWi+gyYOcNGdZiAlt+L8uqISONsE2QbAXWci2VM8fTBzCns/Hxz1uC/dnd34+pbb3c7ljGOy29ZjADWiciZq7YbAn93JJExxdDZg//KcVHti7lvyhQ7mjClRn4vylslIpHA5b6Htmcb+mdMQHvnufHs++6nrMF/HR6+lxbXdnQ7ljFFKr+3Va0EjAQuVtUHRCRSRC5T1Q+djWeMe/bvjOO9f8eQmu4b/BceSf9JU9yOZYwr8nsaai6wCbjatxwPLAasLExA+s+YUSTu+AXVE5QLDqHL4w8T2crv+BxjAlZ+y+ISVe0pIr0BVPWU+MbEGhNI4r6NZdXzL+PJSKSMVCX0shb0GT/B7VjGuC6/ZeERkYr4LtATkUsAe8/CBJS5I0dwZL9v8F/ZUG4fZ4P/jDkjv2UxFlgFNBCRN4BrgPucCmVMUdq0djVfvP521uC/iDYt6fGPf7ody5hixW9Z+E43bcd7FfdVeO+PPUxVDzmczRhHpXk8zBs2nONJCUAaFcrXpfcLNvjPmNz4LQtVVRFZqqptgI+KIJMxjvv8/bfZ/M5K0jMPESQ1aPKXaP760DC3YxlTbOX3NNR6EWmrqhv9r2pM8ZWaksLcocM5mXwQUCpVqkff6ZNs8J8xfuS3LDoCD4rIHuAk3lNRqqotnApmTGH77/zX2LrySzLUO/iv+a0d6dTnPrdjGVMi5LcsbnY0hTEOSj6SxMIR/+DUqYNAEFWqhzNgxnQb1WFMAfi7n0UF4EGgCfADMFtV04simDGFYenUF9iz/nvf4L86XHVPd9rf8je3YxlT4vg7spgPpAGf4z26iALsXUBT7B3av5e3R43jtCcRkXJUC2lIv0mT7WjCmPPkryyiVPUKABGZDWwoyIuLSBdgGhAEvK6qMTmevw6YCrQAeqnqkmzPZeA9mgH41e7KZ/Jr0TNPcWDLz2TqccqWCeH6IX1pfk0Ht2MZU6L5K4u0M1+oanpBJnyISBAwE+iMd5bURhFZrqpbs632K96L+x7L5SVOqWqrfH9DU+rFx21l6VOTSE1PQKQytSIu5b4XJrsdy5iA4K8sWorIcd/XAlT0LZ/5NNRFeWzbDtiR7YZJi4DuQFZZqOoe33OZ5xffGK+FT/yDg7t/9Q3+C+WWJ4bSuHlLt2MZEzD83VY16AJeuz6wN9tyPNC+ANtXEJFYIB2IUdWlF5DFBKitG75k7dTXswb/1W3akrufetbtWMYEnPx+dPZ85HbOSguwfYSq7heRxsAnIvKDqu486xuIDAIGAURERJx/UlMizR42lGMJB1A9TfmydbnjmScIa3iJ27GMCUhOlkU80CDbcjiwP78bq+p+39+7RGQd0BrYmWOdWcAsgOjo6IIUkSnBNq5ZwVdzFpOWeZAyUp2Lo1tzx+NPuh3LmIDmZFlsBCJFpBGwD+gF3J2fDUWkBpCiqqkiUhvvlNvnHUtqSoQ0j4e5Q4eRfCSRM4P/7pkSQ7Vatd2OZkxSZso0AAAQp0lEQVTAc6wsfJ+eGgKsxvvR2Tmq+qOIjAdiVXW5iLQF3gdqALeKyDhVbQY0BV7zvfFdBu97FlvP8a1MKfDZe2/xzTurSddDBElNLu3Unq4PDHY7ljGlhqgGxtmb6OhojY2NdTuGKWSpKSnMfWQ4J0/4Bv9VCWHAjKmUr1TJ7WjGBAQR2aSqfu8Z7ORpKGMuyKrZr7B9zVdkaBLBUosWt91Ax573uh3LmFLJysIUO8cOH+KNR0fb4D9jihErC1OsvDcphl82biFTj1K2TB2u7n8HbW/8q9uxjCn1rCxMsZCwdw9LnnzaN/ivAtVDGzFw+gy3YxljfKwsjOveGv8vftu6k0w9TrmgEDoNvY+oq65zO5YxJhsrC+OaX7Zv4YOnp2QN/qvT6HL6xrzodixjTC6sLIwr5o96jMO/7EX1JOWDQ7n1XyO4+PLmbscyxpyDlYUpUlvXf8bH0+aRlplIGbmIsGat6f3vp92OZYzxw8rCFJnZQx/hWOJvqJ6mQrm69JgwhtAGDd2OZYzJBysL47gNq5azfv77WYP/Gl0VzW0jRrkdyxhTAFYWxjFpHg9zHhnKiaOJQAYVK4Zx75SJVK1R0+1oxpgCsrIwjvj07YV8//7HpOthgqQml3e+mi4DH3I7ljHmPFlZmEJ1MjmZBcMeJeVkIiBUrlKP/jb4z5gSz8rCFJoVs17i5082+Ab/1ablHZ3pcGcft2MZYwqBlYW5YMcOH+I/I0ZzOjURKEvVmg3oP22aDf4zJoBYWZgL8u6Lz/Fr7I++wX8hXD2gB207d3U7ljGmkFlZmPNyYM9O3h0zgdQ07+C/GmGXMGDqNLdjGWMcYmVhCuzNp/5JwvZdZGqyd/Df8PuJavcnt2MZYxxkZWHybef3m1kZM5PUjAREqhDSOIp7n3ve7VjGmCJgZWHyZd7jI0nauy9r8N/fnnqU8Mgot2MZY4qIlYXJ05Yv1vHJSwuyBv/VuyKaXmOecjuWMaaIWVmYXKV5PMwfOZLjh35D1UOFcnXpOXEstes1cDuaMcYFZZx8cRHpIiI/icgOERmdy/PXichmEUkXkR45nusnInG+P/2czGnO9vVHS3m53985dnAPZahIk2uuY/DC160ojCnFHDuyEJEgYCbQGYgHNorIclXdmm21X4H7gMdybFsTGAtEAwps8m17xKm8xjf4b8hQThw7M/ivLvdOed4G/xljHD0N1Q7Yoaq7AERkEdAdyCoLVd3jey4zx7Y3AWtUNcn3/BqgC/CWg3lLtbVvzGPLB59mDf6Luvkabuz3d7djGWOKCSfLoj6wN9tyPND+Aratn3MlERkEDAKIiIg4v5Sl3MnkZBYMHUlKykFAqFy1Hv2n2+A/Y8zZnCwLyeUxLcxtVXUWMAsgOjo6v69tfD58ZRo7/jeWDD1CcJnaXHnXzVx7W0+3YxljiiEnyyIeyP6OaDiwvwDbdsix7bpCSWVISviNtx4f8/vgv1oR9J861Qb/GWPOycmy2AhEikgjYB/QC7g7n9uuBiaISA3f8o3AE4UfsfRZHPMM8d9uI1OPUbZMCNf9vTetOnR2O5YxpphzrCxUNV1EhuD9wR8EzFHVH0VkPBCrqstFpC3wPlADuFVExqlqM1VNEpGn8RYOwPgzb3ab87N/ZxzvjY3xDf6rSM36Teg/earbsYwxJYSoBsap/ujoaI2NjXU7RrH0n3+N5mDcL1mD/7r842EiW0W7HcsYUwyIyCZV9fsDwa7gDmBx38ay6vlX8JwZ/NekGfc+O9HtWMaYEsjKIkDNe3QESfv2oXqK8sGh3D5+NPUuiXQ7ljGmhLKyCDDfrlvDZ6+95Rv8V43wVs2564l/ux3LGFPCWVkEiDSPh3kjRnD8UALgoUL5uvR+4RlqhtZ1O5oxJgBYWQSAL5YtJnbRR6RnHiJIanDJtddw6+ARbscyxgQQK4sSLDUlhbnDRnDy+EEgk4qVwug3fTKVq1Z1O5oxJsBYWZRQa+a/ztaVn5OuhwkuU4tmt1zHDfcMdDuWMSZAWVmUMCeTk5n/yEhOnToIlKHKRfUZMHOGjeowxjjKyqIEWT5jEru++DZr8F+7u7tx9a23ux3LGFMKWFmUAIf27+XtUeM47UlEpBzV6lxMv8lT7GjCGFNkrCyKuXcmjGPf9z9nDf7r8PC9tLi2o9uxjDGljJVFMRUft5WlT00iNT0BkUrUCo/kvklT3I5ljCmlrCyKoYX/HMXBnb+geoJywSF0HTWES1pc6XYsY0wpZmVRjGzf9DVrJr2GJyORMlKV0Mta0Gf8BLdjGWOMlUVxMXfkcI7s3+8d/Fc2lDueeZKwhpe4HcsYYwArC9dtWruaL15fRFrmQcpINSLatKTHP/7pdixjjDmLlYVL0jwe5g4bTnJSApBmg/+MMcWalYULPn//bTa/szJr8F9kh7bc8uBQt2MZY8w5WVkUodSUFOY+MoKTJxIBpVKlevSdPskG/xljij0riyKyeu6rbFv9JRmaRLDUokX3TnTs3dftWMYYky9WFg5LPpLEwhGjOHUqEQiiSvVwBsyYbqM6jDEliqNlISJdgGlAEPC6qsbkeL48sABoAxwGeqrqHhFpCGwDfvKtul5VH3QyqxOWTn2B3eu/I1OPUrZMHdrf0532t/zN7VjGGFNgjpWFiAQBM4HOQDywUUSWq+rWbKsNBI6oahMR6QVMBHr6ntupqq2cyuekPwz+C2lIv0mT7WjCGFNiOXlk0Q7Yoaq7AERkEdAdyF4W3YGnfF8vAV4SEXEwk+MWPfMUB7b8TKYep2yZEK4f0pfm13RwO5YxxlwQJ8uiPrA323I80P5c66hquogcA2r5nmskIt8Ax4Exqvq5g1kv2C/bt/DB01N8g/8qUzviMvq9MMntWMYYUyicLIvcjhA0n+scACJU9bCItAGWikgzVT1+1sYig4BBABEREYUQ+fwsGP04h/bs9Q3+C+WWJ4bSuHlL1/IYY0xhc7Is4oEG2ZbDgf3nWCdeRIKBakCSqiqQCqCqm0RkJ3ApEJt9Y1WdBcwCiI6OzllEjtu64UvWTn09a/Bf3aYtufupZ4s6hjHGOM7JstgIRIpII2Af0Au4O8c6y4F+wFdAD+ATVVURqYO3NDJEpDEQCexyMGuBzR42lGMJB1A9TfmydbnzuTGENmjodixjjHGEY2Xhew9iCLAa70dn56jqjyIyHohV1eXAbGChiOwAkvAWCsB1wHgRSQcygAdVNcmprAWx8b8f8tXcd32D/6pzcdsrueOxJ9yOZYwxjhLvGZ+SLzo6WmNjY/2veJ7SPB7mDh1G8pFEIJ2KFerQZ3IM1WrVdux7GmOM00Rkk6pG+1vPruDOh3WL3+C7d9eQrocIkppc2qk9XR8Y7HYsY4wpMlYWeUhNSWHOI8NIOXEQgEpVwhgwYxrlK1VyOZkxxhQtK4tzWDX7Fbav+co3+K82LW7rRMee97odyxhjXGFlkcOxw4d4Y+RoTp0+CARTtXo4/W3wnzGmlLOyyOa9STH8snFL1uC/q/vfQdsb/+p2LGOMcZ2VBZCwdw9Lnnia02mJiFSgemgjBk6f4XYsY4wpNkp9WXz61gK+XbaKTD1OuaAQOg2/n6h2f3I7ljHGFCtl3A7gtpbX30gZKUedRpfzyJtzrCiMMSYXpf7IomZoXYa9Nc/tGMYYU6yV+iMLY4wx/llZGGOM8cvKwhhjjF9WFsYYY/yysjDGGOOXlYUxxhi/rCyMMcb4ZWVhjDHGr4C5U56IHAR+uYCXqA0cKqQ4JUVp2+fStr9g+1xaXMg+X6yqdfytFDBlcaFEJDY/txYMJKVtn0vb/oLtc2lRFPtsp6GMMcb4ZWVhjDHGLyuL381yO4ALSts+l7b9Bdvn0sLxfbb3LIwxxvhlRxbGGGP8KlVlISJzRCRRRLac43kRkekiskNEvheRK4s6Y2HLxz738e3r9yLypYi0LOqMhc3fPmdbr62IZIhIj6LK5oT87K+IdBCRb0XkRxH536LM54R8/H9dTUQ+EJHvfPvcv6gzFjYRaSAin4rINt8+DctlHcd+hpWqsgDmAV3yeP5mINL3ZxDwShFkcto88t7n3cBfVLUF8DSBcb53HnnvMyISBEwEVhdFIIfNI4/9FZHqwMtAN1VtBtxZRLmcNI+8/xsPBraqakugAzBJRMoVQS4npQOPqmpT4CpgsIhE5VjHsZ9hpaosVPUzICmPVboDC9RrPVBdRMKKJp0z/O2zqn6pqkd8i+uB8CIJ5qB8/HcGeAR4F0h0PpGz8rG/dwPvqeqvvvVLwz4rUFVEBKjiWze9KLI5RVUPqOpm39fJwDagfo7VHPsZVqrKIh/qA3uzLcfzx/8YgWwgsNLtEE4TkfrAbcCrbmcpIpcCNURknYhsEpG+bgcqAi8BTYH9wA/AMFXNdDdS4RGRhkBr4OscTzn2M6zU34M7B8nlsVLxcTER6Yi3LP7sdpYiMBUYpaoZ3l88A14w0AboBFQEvhKR9ar6s7uxHHUT8C1wPXAJsEZEPlfV4+7GunAiUgXvUfHwXPbHsZ9hVhZniwcaZFsOx/ubSUATkRbA68DNqnrY7TxFIBpY5CuK2kBXEUlX1aXuxnJMPHBIVU8CJ0XkM6AlEMhl0R+IUe+1ATtEZDdwObDB3VgXRkTK4i2KN1T1vVxWcexnmJ2GOttyoK/vEwVXAcdU9YDboZwkIhHAe8C9Af6bZhZVbaSqDVW1IbAEeDiAiwJgGXCtiASLSCWgPd7z3YHsV7xHUohIKHAZsMvVRBfI9/7LbGCbqk4+x2qO/QwrVUcWIvIW3k9G1BaReGAsUBZAVV8FVgBdgR1ACt7fTkq0fOzzv4FawMu+37TTS/oQtnzsc0Dxt7+quk1EVgHfA5nA66qa58eKi7t8/Dd+GpgnIj/gPTUzSlVL+iTaa4B7gR9E5FvfY08CEeD8zzC7gtsYY4xfdhrKGGOMX1YWxhhj/LKyMMYY45eVhTHGGL+sLIwxxvhlZWFMHkQkXESWiUiciOwUkWm5DaQTkXoisiQfr7fCN9jvfLI8JSKPnc+2xlwoKwtjzsF3EdR7wFJVjcQ7Y6kK8GyO9YJVdb+q+h11rqpdVfWoI4GNcVCpuijPmAK6HjitqnMBfLOkRgC7feMjOgIVgMoiMgD4UFWb+66Snod3vMQ2oCEwWFVjRWQP3nEjVfAObfw/4E/APqC7qp4SkQfwjpcuh/fiqntVNaWI9tmYXNmRhTHn1gzYlP0B3+C2X/H+onU10E9Vr8+x3cPAkWz3CGlzjtePBGb67jFxFLjD9/h7qtrWdy+GbXgHPBrjKisLY85NyH1i55nH16hqbvdU+DOwCMA3VuP7c7z+blU9M7ZhE94jEIDmIvK5b1RFH7ylZYyrrCyMObcf8Z4yyiIiF+Gd6pkBnDzHdvmde56a7esMfj8tPA8YoqpXAOPwnuoyxlVWFsac21qg0pmbBfluxToJ7w/zvN5D+D/gLt82UcAVBfy+VYEDvnHUfQq4rTGOsLIw5hx890K4DbhTROLw3v/hNN5Jn3l5GagjIt8Do/CehjpWgG/9L7x3QFsDbC9obmOcYFNnjSlkviOQsqp6WkQuwXuEcqmqelyOZsx5s4/OGlP4KgGf+k4jCfCQFYUp6ezIwhhjjF/2noUxxhi/rCyMMcb4ZWVhjDHGLysLY4wxfllZGGOM8cvKwhhjjF//D/ZyrTqXJXcVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall R^2:\n",
      "0.43322339049927755\n"
     ]
    }
   ],
   "source": [
    "# Store values from loops.\n",
    "preds = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "uniquex = df['partner'].unique()\n",
    "\n",
    "# Iterate through decision trees, each time using the residuals\n",
    "# from the previous tree as the inputs.\n",
    "for m in range(0, 101):\n",
    "    \n",
    "    # Initialize and fit the tree. Set the max depth to 2.\n",
    "    decision_tree = tree.DecisionTreeClassifier(max_depth=2)\n",
    "    decision_tree.fit(X2,y)\n",
    "    \n",
    "    # Get and store predicted values.\n",
    "    pred = decision_tree.predict(X2)\n",
    "    preds['pred{}'.format(m)] = pred\n",
    "    \n",
    "    # Residuals.\n",
    "    y = y - pred\n",
    "\n",
    "    # Output every 20 iterations.\n",
    "    if m % 20 == 0:\n",
    "        print('Weak learner {} R^2: {}'.format(m, decision_tree.score(X2, y)))\n",
    "        labels = labels + [m]\n",
    "        bestpred = preds.sum(axis=1)\n",
    "        plt.plot(uniquex, np.poly1d(np.polyfit(df['partner'], bestpred, 1))(uniquex))\n",
    "       \n",
    "plt.legend(labels)\n",
    "plt.xlabel('Original')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "predicted = preds.sum(axis=1)\n",
    "\n",
    "print('Overall R^2:')\n",
    "print(np.corrcoef(df['partner'], predicted)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.01258247659966242\n",
      "Percent Type II errors: 0.08485499462943072\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08098159509202454\n",
      "Percent Type II errors: 0.17116564417177915\n"
     ]
    }
   ],
   "source": [
    "# We will make 800 iterations, use 4-deep trees, and set our loss function. \n",
    "params = {'n_estimators': 800,\n",
    "         'max_depth': 4,\n",
    "         'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X2_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X2_train)\n",
    "predict_test = clf.predict(X2_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... max_depth=2, n_estimators=200, score=0.769, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... max_depth=2, n_estimators=200, score=0.779, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... max_depth=2, n_estimators=200, score=0.744, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.715, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.718, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.782, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.782, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.733, total=   0.5s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.739, total=   0.6s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=200, score=0.750, total=   0.6s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=500, score=0.753, total=   1.5s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=500, score=0.783, total=   1.3s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=500, score=0.725, total=   1.5s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=500, score=0.686, total=   1.5s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] ....... max_depth=2, n_estimators=500, score=0.729, total=   1.3s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5f175e2bc7c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Fit the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#return best parameters and best score for training model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m                 \u001b[1;31m# no need to fancy index w/ no subsampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_score_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y, raw_predictions, sample_weight)\u001b[0m\n\u001b[0;32m    608\u001b[0m             return (-2 / sample_weight.sum() * np.sum(\n\u001b[0;32m    609\u001b[0m                 sample_weight * ((y * raw_predictions) -\n\u001b[1;32m--> 610\u001b[1;33m                                  np.logaddexp(0, raw_predictions))))\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnegative_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set grid parameters\n",
    "grid_params = {'n_estimators': [200, 500, 800, 1000],\n",
    "         'max_depth': [2, 4, 6],}\n",
    "# Use the grid\n",
    "grid = GridSearchCV(clf, grid_params, cv=10, verbose=3)\n",
    "\n",
    "#Fit the data\n",
    "grid.fit(X2_train, y_train)\n",
    "\n",
    "#return best parameters and best score for training model.\n",
    "print('Best parameters for training model:')\n",
    "print(grid.best_params_)\n",
    "print('Best Score for training model:')\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model.\n",
    "\n",
    "# Establish and fit the model, with a single, 100 perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "mlp.fit(X2_train, y_train)\n",
    "\n",
    "mlp.score(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(mlp, X2_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on the test set.\n",
    "\n",
    "# Let's see how the testing data performs.\n",
    "mlp_pred = mlp.predict(X2_test)\n",
    "\n",
    "confusion_matrix(y_test, mlp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for mlp\n",
    "mlp_params = [{'hidden_layer_sizes': [(100,4), (500,4), (1000,4)],\n",
    "              'alpha': [.000001, .00001, .0001, .001, 1, 10],\n",
    "              'max_iter': [200, 400, 600]}]\n",
    "\n",
    "# Search for the best paramters. \n",
    "mlp_grid = GridSearchCV(mlp, mlp_params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid and obtain results\n",
    "mlp_grid.fit(X2_train, y_train)\n",
    "\n",
    "# Return best parameters and best score\n",
    "print('Best parameters:')\n",
    "print(mlp_grid.best_params_)\n",
    "print('Best Score:')\n",
    "print(mlp_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(hidden_layer_sizes=(500,4), alpha=1, max_iter=400)\n",
    "mlp2.fit(X2_train, y_train)\n",
    "mlp2.score(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(mlp2, X2_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_pred = mlp2.predict(X2_test)\n",
    "\n",
    "confusion_matrix(y_test, mlp2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3 = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp3.fit(X2_train, y_train)\n",
    "\n",
    "mlp3.score(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(mlp3, X2_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3_pred = mlp3.predict(X2_test)\n",
    "\n",
    "confusion_matrix(y_test, mlp3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4 = MLPClassifier(hidden_layer_sizes=(10000,))\n",
    "mlp4.fit(X2_train, y_train)\n",
    "mlp4.score(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(mlp4, X2_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4_pred = mlp4.predict(X2_test)\n",
    "\n",
    "confusion_matrix(y_test, mlp4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
