{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing which text to build an NLP from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing two similarly themed literary works\n",
    "shakes = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "milton = gutenberg.raw('milton-paradise.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and Parsing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    text = re.sub(r'CHAPTER \\d+', '', text)\n",
    "    text = re.sub(\"\\\\n\\\\n.*?\\\\n\\\\n\", '', text)\n",
    "  \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean both documents\n",
    "shakes = text_cleaner(shakes)\n",
    "milton = text_cleaner(milton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spacy and analyze the documents\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# Clean Caesar first\n",
    "shakes_doc = nlp(shakes)\n",
    "milton_doc = nlp(milton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Thunder, and, Lightning, .)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Enter, three, Witches, .)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, .)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(When, shall, we, three, meet, againe, ?)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(In, Thunder, ,, Lightning, ,, or, in, Raine, ...</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0                       (Thunder, and, Lightning, .)  Shakes\n",
       "1                         (Enter, three, Witches, .)  Shakes\n",
       "2                                             (1, .)  Shakes\n",
       "3          (When, shall, we, three, meet, againe, ?)  Shakes\n",
       "4  (In, Thunder, ,, Lightning, ,, or, in, Raine, ...  Shakes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "shakes_sents = [[sent, \"Shakes\"] for sent in shakes_doc.sents]\n",
    "milton_sents = [[sent, \"Milton\"] for sent in milton_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(shakes_sents + milton_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5264"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3511"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "shakeswords = bag_of_words(shakes_doc)\n",
    "miltonwords = bag_of_words(milton_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(shakeswords + miltonwords)\n",
    "\n",
    "# How many words we got?\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likeness</th>\n",
       "      <th>lauish</th>\n",
       "      <th>transform</th>\n",
       "      <th>donal</th>\n",
       "      <th>Strange</th>\n",
       "      <th>Morrow</th>\n",
       "      <th>speech</th>\n",
       "      <th>reflection</th>\n",
       "      <th>Menteth</th>\n",
       "      <th>shrine</th>\n",
       "      <th>...</th>\n",
       "      <th>receiu'd</th>\n",
       "      <th>Liege</th>\n",
       "      <th>Heere</th>\n",
       "      <th>journey</th>\n",
       "      <th>binde</th>\n",
       "      <th>Charme</th>\n",
       "      <th>ouerthrowne</th>\n",
       "      <th>plague</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Thunder, and, Lightning, .)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Enter, three, Witches, .)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, .)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(When, shall, we, three, meet, againe, ?)</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(In, Thunder, ,, Lightning, ,, or, in, Raine, ...</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  likeness lauish transform donal Strange Morrow speech reflection Menteth  \\\n",
       "0        0      0         0     0       0      0      0          0       0   \n",
       "1        0      0         0     0       0      0      0          0       0   \n",
       "2        0      0         0     0       0      0      0          0       0   \n",
       "3        0      0         0     0       0      0      0          0       0   \n",
       "4        0      0         0     0       0      0      0          0       0   \n",
       "\n",
       "  shrine  ... receiu'd Liege Heere journey binde Charme ouerthrowne plague  \\\n",
       "0      0  ...        0     0     0       0     0      0           0      0   \n",
       "1      0  ...        0     0     0       0     0      0           0      0   \n",
       "2      0  ...        0     0     0       0     0      0           0      0   \n",
       "3      0  ...        0     0     0       0     0      0           0      0   \n",
       "4      0  ...        0     0     0       0     0      0           0      0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0                       (Thunder, and, Lightning, .)      Shakes  \n",
       "1                         (Enter, three, Witches, .)      Shakes  \n",
       "2                                             (1, .)      Shakes  \n",
       "3          (When, shall, we, three, meet, againe, ?)      Shakes  \n",
       "4  (In, Thunder, ,, Lightning, ,, or, in, Raine, ...      Shakes  \n",
       "\n",
       "[5 rows x 3513 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.974350854971501\n",
      "\n",
      "Test set score: 0.869420702754036\n"
     ]
    }
   ],
   "source": [
    "# random forest fitting \n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83886256, 0.84335443, 0.87955626, 0.86846276, 0.84627575])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overfitting has occurred but test set still did okay.\n",
    "# Lets cross validate.\n",
    "\n",
    "cross_val_score(rfc, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8055731475617479\n",
      "\n",
      "Test set score: 0.7934472934472935\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting.\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model\n",
    "fit_clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75671406, 0.78006329, 0.79397781, 0.78763867, 0.78129952])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores are more consistent. Overfitting hasn't seem to have occurred.\n",
    "cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3158, 3511) (3158,)\n",
      "Training set score: 0.9648511716276124\n",
      "\n",
      "Test set score: 0.9088319088319088\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90363349, 0.90348101, 0.90015848, 0.91600634, 0.8858954 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like overfitting has occurred. I will attempt to fix that later. \n",
    "cross_val_score(lr, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'max_depth': 8, 'max_features': 2, 'n_estimators': 1000}\n",
      "Best Score:\n",
      "0.9103863204559848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Use GS-CV in order to find the optimal parameters.\n",
    "clf_parameters = {\n",
    "             'n_estimators':[100,200,500,1000],\n",
    "              'max_depth':[2,4,6,8],\n",
    "              'max_features':[2,4,6,8]\n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(clf, clf_parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "#Fit the logistic regression \n",
    "clf_grid.fit(X_train, y_train)\n",
    "\n",
    "#return best parameters and best score\n",
    "print('Best parameters:')\n",
    "print(clf_grid.best_params_)\n",
    "print('Best Score:')\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92259084, 0.88607595, 0.91283677, 0.9207607 , 0.90649762])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Improved the score by increasing iterations and features.\n",
    "clf = ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                         max_depth=8, max_features=4)\n",
    "\n",
    "cross_val_score(clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9028436 , 0.87914692, 0.91232227, 0.9047619 , 0.88809524])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores are consistent but lets try it on a test set.\n",
    "cross_val_score(clf, X_test, y_test, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf-idf function\n",
    "def document_freq(data, sentences, common_words, doc_names, doc_words):\n",
    "    \n",
    "    # initialize df\n",
    "    df = pd.DataFrame(columns = common_words)\n",
    "    df.iloc[:, 0] = [0, 0, 0, 0, 0]\n",
    "    df.loc[:, common_words] = 0\n",
    "    df.rename(index={0:'df', 1:'cf', 2:'idf', 3:'Shakes', 4:'Milton'}, inplace=True)\n",
    "    \n",
    "    for word in common_words:\n",
    "        # find document frequency & collection frequency\n",
    "        df.loc['df', word] = data[data[word] > 0][word].count()\n",
    "        df.loc['cf', word] = data.loc[:, word].sum()\n",
    "        \n",
    "        # find idf\n",
    "        df.loc['idf', word] = np.log2(len(sentences)/df.loc['df', word])\n",
    "        \n",
    "    # assign the idf value to the documents\n",
    "    for word in df.columns:\n",
    "        for i in range(len(doc_names)):\n",
    "            if word in doc_words[i]:\n",
    "                df.loc[doc_names[i], word] = df.loc['idf', word]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likeness</th>\n",
       "      <th>lauish</th>\n",
       "      <th>transform</th>\n",
       "      <th>donal</th>\n",
       "      <th>Strange</th>\n",
       "      <th>Morrow</th>\n",
       "      <th>speech</th>\n",
       "      <th>reflection</th>\n",
       "      <th>Menteth</th>\n",
       "      <th>shrine</th>\n",
       "      <th>...</th>\n",
       "      <th>audience</th>\n",
       "      <th>interprete</th>\n",
       "      <th>receiu'd</th>\n",
       "      <th>Liege</th>\n",
       "      <th>Heere</th>\n",
       "      <th>journey</th>\n",
       "      <th>binde</th>\n",
       "      <th>Charme</th>\n",
       "      <th>ouerthrowne</th>\n",
       "      <th>plague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>10.040016</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>8.455053</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>...</td>\n",
       "      <td>9.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>8.776981</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>9.776981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>8.455053</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>9.776981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.455053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>...</td>\n",
       "      <td>9.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.776981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.776981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         likeness     lauish  transform      donal    Strange     Morrow  \\\n",
       "df       5.000000   1.000000   4.000000   2.000000   1.000000   1.000000   \n",
       "cf       6.000000   1.000000   4.000000   2.000000   1.000000   1.000000   \n",
       "idf     10.040016  12.361944  10.361944  11.361944  12.361944  12.361944   \n",
       "Shakes   0.000000  12.361944   0.000000  11.361944  12.361944  12.361944   \n",
       "Milton  10.040016   0.000000  10.361944   0.000000   0.000000   0.000000   \n",
       "\n",
       "           speech  reflection    Menteth     shrine  ...  audience  \\\n",
       "df      15.000000    3.000000   2.000000   5.000000  ...  8.000000   \n",
       "cf      15.000000    3.000000   2.000000   5.000000  ...  8.000000   \n",
       "idf      8.455053   10.776981  11.361944  10.040016  ...  9.361944   \n",
       "Shakes   8.455053   10.776981  11.361944   0.000000  ...  0.000000   \n",
       "Milton   8.455053    0.000000   0.000000  10.040016  ...  9.361944   \n",
       "\n",
       "        interprete   receiu'd      Liege      Heere    journey      binde  \\\n",
       "df        1.000000   2.000000   3.000000   3.000000  12.000000   1.000000   \n",
       "cf        1.000000   2.000000   3.000000   3.000000  12.000000   1.000000   \n",
       "idf      12.361944  11.361944  10.776981  10.776981   8.776981  12.361944   \n",
       "Shakes   12.361944  11.361944  10.776981  10.776981   0.000000  12.361944   \n",
       "Milton    0.000000   0.000000   0.000000   0.000000   8.776981   0.000000   \n",
       "\n",
       "           Charme  ouerthrowne    plague  \n",
       "df       5.000000     1.000000  6.000000  \n",
       "cf       5.000000     1.000000  6.000000  \n",
       "idf     10.040016    12.361944  9.776981  \n",
       "Shakes  10.040016    12.361944  9.776981  \n",
       "Milton   0.000000     0.000000  9.776981  \n",
       "\n",
       "[5 rows x 3511 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arrays to identify and hold my words.\n",
    "doc_names = ['Shakes', 'Milton']\n",
    "doc_words = [shakeswords, miltonwords]\n",
    "tf_idf = document_freq(word_counts, sentences, common_words, doc_names, doc_words)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>Shakes</th>\n",
       "      <th>Milton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>likeness</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lauish</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.361944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strange</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            df   cf        idf     Shakes     Milton\n",
       "likeness   5.0  6.0  10.040016   0.000000  10.040016\n",
       "lauish     1.0  1.0  12.361944  12.361944   0.000000\n",
       "transform  4.0  4.0  10.361944   0.000000  10.361944\n",
       "donal      2.0  2.0  11.361944  11.361944   0.000000\n",
       "Strange    1.0  1.0  12.361944  12.361944   0.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make it so that the rows become the columns. \n",
    "tf_idf = tf_idf.T\n",
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>Shakes</th>\n",
       "      <th>Milton</th>\n",
       "      <th>Shakes_threshold</th>\n",
       "      <th>Milton_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>likeness</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lauish</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strange</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            df   cf        idf     Shakes     Milton  Shakes_threshold  \\\n",
       "likeness   5.0  6.0  10.040016   0.000000  10.040016                 0   \n",
       "lauish     1.0  1.0  12.361944  12.361944   0.000000                 1   \n",
       "transform  4.0  4.0  10.361944   0.000000  10.361944                 0   \n",
       "donal      2.0  2.0  11.361944  11.361944   0.000000                 1   \n",
       "Strange    1.0  1.0  12.361944  12.361944   0.000000                 1   \n",
       "\n",
       "           Milton_threshold  \n",
       "likeness                  1  \n",
       "lauish                    0  \n",
       "transform                 1  \n",
       "donal                     0  \n",
       "Strange                   0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set up a threshold to count and see which word belongs where.\n",
    "threshold = 5\n",
    "tf_idf['Shakes_threshold'] = 0\n",
    "tf_idf['Milton_threshold'] = 0\n",
    "\n",
    "tf_idf['Shakes_threshold'] = np.where(tf_idf['Shakes'] > threshold, 1, 0)\n",
    "tf_idf['Milton_threshold'] = np.where(tf_idf['Milton'] > threshold, 1, 0)\n",
    "\n",
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up a way to determine which word goes into which group.\n",
    "# default with both\n",
    "tf_idf['source'] = 'both'\n",
    "\n",
    "# Create a method\n",
    "def determine_who(df):\n",
    "    # Create a loop that iterates through each row and determines where it goes.\n",
    "    for i in range(len(df)):\n",
    "        # make a counter\n",
    "        flag = 0\n",
    "        source = 'Both'\n",
    "        \n",
    "        if (df.iloc[i, 5] == 1):\n",
    "            flag = 1\n",
    "            source = 'Shakes'\n",
    "           \n",
    "        if (df.iloc[i, 6] == 1):\n",
    "            if (flag == 1):\n",
    "                continue\n",
    "            flag = 1\n",
    "            source = 'Milton'\n",
    "            \n",
    "        df.iloc[i, 7] = source\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "      <th>Shakes</th>\n",
       "      <th>Milton</th>\n",
       "      <th>Shakes_threshold</th>\n",
       "      <th>Milton_threshold</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>likeness</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lauish</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strange</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morrow</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.455053</td>\n",
       "      <td>8.455053</td>\n",
       "      <td>8.455053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reflection</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Menteth</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrine</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let</th>\n",
       "      <td>124.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>5.407747</td>\n",
       "      <td>5.407747</td>\n",
       "      <td>5.407747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>befall</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.040016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.022094</td>\n",
       "      <td>6.022094</td>\n",
       "      <td>6.022094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thou'rt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disobey</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.776981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wracke</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>55.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.580584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.580584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ice</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.776981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.776981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thou</th>\n",
       "      <td>393.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>3.743558</td>\n",
       "      <td>3.743558</td>\n",
       "      <td>3.743558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strange</th>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7.152490</td>\n",
       "      <td>7.152490</td>\n",
       "      <td>7.152490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurl</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.040016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chamberlaines</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appall</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>11.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix'd</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glitter</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.361944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.776981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.776981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectation</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.361944</td>\n",
       "      <td>9.361944</td>\n",
       "      <td>9.361944</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crueltie</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>12.361944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shakes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  df     cf        idf     Shakes     Milton  \\\n",
       "likeness         5.0    6.0  10.040016   0.000000  10.040016   \n",
       "lauish           1.0    1.0  12.361944  12.361944   0.000000   \n",
       "transform        4.0    4.0  10.361944   0.000000  10.361944   \n",
       "donal            2.0    2.0  11.361944  11.361944   0.000000   \n",
       "Strange          1.0    1.0  12.361944  12.361944   0.000000   \n",
       "Morrow           1.0    1.0  12.361944  12.361944   0.000000   \n",
       "speech          15.0   15.0   8.455053   8.455053   8.455053   \n",
       "reflection       3.0    3.0  10.776981  10.776981   0.000000   \n",
       "Menteth          2.0    2.0  11.361944  11.361944   0.000000   \n",
       "shrine           5.0    5.0  10.040016   0.000000  10.040016   \n",
       "let            124.0  128.0   5.407747   5.407747   5.407747   \n",
       "befall          10.0   11.0   9.040016   0.000000   9.040016   \n",
       "new             81.0   86.0   6.022094   6.022094   6.022094   \n",
       "thou'rt          1.0    1.0  12.361944  12.361944   0.000000   \n",
       "metal            4.0    5.0  10.361944   0.000000  10.361944   \n",
       "disobey          3.0    4.0  10.776981   0.000000  10.776981   \n",
       "wracke           2.0    2.0  11.361944  11.361944   0.000000   \n",
       "pain            55.0   57.0   6.580584   0.000000   6.580584   \n",
       "ice              6.0    6.0   9.776981   0.000000   9.776981   \n",
       "proper           5.0    5.0  10.040016   0.000000  10.040016   \n",
       "thou           393.0  449.0   3.743558   3.743558   3.743558   \n",
       "strange         37.0   38.0   7.152490   7.152490   7.152490   \n",
       "hurl             5.0    5.0  10.040016   0.000000  10.040016   \n",
       "Chamberlaines    1.0    1.0  12.361944  12.361944   0.000000   \n",
       "appall           2.0    2.0  11.361944  11.361944   0.000000   \n",
       "fix'd            1.0    1.0  12.361944  12.361944   0.000000   \n",
       "glitter          4.0    4.0  10.361944   0.000000  10.361944   \n",
       "story            6.0    6.0   9.776981   0.000000   9.776981   \n",
       "expectation      8.0    8.0   9.361944   9.361944   9.361944   \n",
       "Crueltie         1.0    1.0  12.361944  12.361944   0.000000   \n",
       "\n",
       "               Shakes_threshold  Milton_threshold  source  \n",
       "likeness                      0                 1  Milton  \n",
       "lauish                        1                 0  Shakes  \n",
       "transform                     0                 1  Milton  \n",
       "donal                         1                 0  Shakes  \n",
       "Strange                       1                 0  Shakes  \n",
       "Morrow                        1                 0  Shakes  \n",
       "speech                        1                 1    both  \n",
       "reflection                    1                 0  Shakes  \n",
       "Menteth                       1                 0  Shakes  \n",
       "shrine                        0                 1  Milton  \n",
       "let                           1                 1    both  \n",
       "befall                        0                 1  Milton  \n",
       "new                           1                 1    both  \n",
       "thou'rt                       1                 0  Shakes  \n",
       "metal                         0                 1  Milton  \n",
       "disobey                       0                 1  Milton  \n",
       "wracke                        1                 0  Shakes  \n",
       "pain                          0                 1  Milton  \n",
       "ice                           0                 1  Milton  \n",
       "proper                        0                 1  Milton  \n",
       "thou                          0                 0    Both  \n",
       "strange                       1                 1    both  \n",
       "hurl                          0                 1  Milton  \n",
       "Chamberlaines                 1                 0  Shakes  \n",
       "appall                        1                 0  Shakes  \n",
       "fix'd                         1                 0  Shakes  \n",
       "glitter                       0                 1  Milton  \n",
       "story                         0                 1  Milton  \n",
       "expectation                   1                 1    both  \n",
       "Crueltie                      1                 0  Shakes  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was testing the output and accidentally created another row. \n",
    "tf_idf_test = determine_who(tf_idf)\n",
    "\n",
    "tf_idf_test.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.820919820919821\n",
      "\n",
      "Test set score: 0.7912713472485768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Finally time to test the models! \n",
    "# Drop everything except for the tf-idf values\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y2 = tf_idf_test['source']\n",
    "X2 = tf_idf_test.drop(['source', 'Shakes_threshold',\n",
    "                'Milton_threshold' ,'Shakes', 'Milton'], axis=1)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, \n",
    "                                                    Y2,\n",
    "                                                    test_size=0.3)\n",
    "train = rfc.fit(X2_train, y2_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X2_train, y2_train))\n",
    "print('\\nTest set score:', rfc.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76923077, 0.75609756, 0.79837067, 0.79387755, 0.79387755])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate the rfc model. \n",
    "cross_val_score(rfc, X2_train, y2_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2457, 3) (2457,)\n",
      "Training set score: 0.7431827431827431\n",
      "\n",
      "Test set score: 0.7504743833017078\n"
     ]
    }
   ],
   "source": [
    "# logistic regression fitting\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X2_train, y2_train)\n",
    "print(X2_train.shape, y2_train.shape)\n",
    "print('Training set score:', lr.score(X2_train, y2_train))\n",
    "print('\\nTest set score:', lr.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\liuth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.72672065, 0.73577236, 0.75560081, 0.75102041, 0.74489796])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X2_train, y2_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8156288156288156\n",
      "\n",
      "Test set score: 0.7922201138519924\n"
     ]
    }
   ],
   "source": [
    "clf2 = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# Gradient Boosting Model.\n",
    "train = clf2.fit(X2_train, y2_train)\n",
    "\n",
    "print('Training set score:', clf2.score(X2_train, y2_train))\n",
    "print('\\nTest set score:', clf2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77530364, 0.76626016, 0.80855397, 0.80612245, 0.79183673])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf2, X2_train, y2_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   47.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}\n",
      "Best Score:\n",
      "0.7891737891737892\n"
     ]
    }
   ],
   "source": [
    "# Lets improve the GB model since it will be faster than the random forest. \n",
    "# Use GS-CV in order to find the optimal parameters.\n",
    "clf_parameters = {\n",
    "             'n_estimators':[100,200,500,1000],\n",
    "              'max_depth':[2,4,6,8],\n",
    "             'max_features':['auto']\n",
    "}\n",
    "\n",
    "clf_grid = GridSearchCV(clf, clf_parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "#Fit the logistic regression \n",
    "clf_grid.fit(X2_train, y2_train)\n",
    "\n",
    "#return best parameters and best score\n",
    "print('Best parameters:')\n",
    "print(clf_grid.best_params_)\n",
    "print('Best Score:')\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
